---
title: Hierarchical Reinforcement Learning (HRL) for Safe Dynamic Legged Locomotion
summary: Our research project aims to advance the capabilities of legged robots via novel Hierarchical Reinforcement Learning (HRL) algorithms, enabling them to achieve efficient and adaptive locomotion in complex environments. 
tags:
  - learning
  - humanoid
  - exoskeleton
date: '2022-04-15T00:00:00Z'
featured: true

image:
  caption: Illustration of proposed project goals.
  focal_point: Smart
  preview_only: false

reading_time: true
profile: false
pager: true
---


### Introduction
In this project, we focus on developing a hierarchical reinforcement learning framework for robust and safe legged locomotion. In the field of cognitive science, it has been observed that humans and animals learn complex behaviors in a hierarchical manner to adapt to the complexities of real-world environments. This project aims to apply this concept to legged robots, enabling robots to efficiently explore high-dimensional behavior spaces and overcome challenges faced by traditional end-to-end reinforcement learning algorithms.

### Research Focus

1. **Skill Acquisition**: We are developing algorithms that enable legged robots to acquire a repertoire of skills through reinforcement learning. By decomposing locomotion tasks into sub-tasks, such as walking at different speeds, turning, and stair climbing, we can train the robot to learn each skill individually. This hierarchical approach allows for faster learning and better generalization to new environments.

2. **Skill Coordination**: Once the robot has learned a set of skills, the challenge lies in coordinating these skills to achieve robust and safe locomotion. Our research focuses on developing hierarchical policies that can effectively combine and sequence the learned skills, allowing the robot to adapt to different terrains, navigate obstacles, and maintain stability during locomotion.

3. **Robustness and Safety**: Ensuring robust and safe locomotion is of utmost importance, especially in real-world scenarios. We are investigating techniques to enhance the robustness of the learned policies, making them more resilient to disturbances, uncertainties, and changes in the environment. Additionally, we are developing safety-aware algorithms that enable legged robots to avoid collisions, recover from falls, and operate within predefined safety constraints.


### Applications
The research in hierarchical reinforcement learning for robust and safe legged locomotion has numerous potential applications across various domains. Some of the areas where our research can have a significant impact include:

1. **Robotics in Hazardous Environments**: Legged robots equipped with robust and safe locomotion capabilities can be deployed in hazardous environments, such as disaster-stricken areas or nuclear facilities, to perform tasks that are too dangerous for humans.

2. **Exploration and Surveillance**: By enabling legged robots to navigate challenging terrains and adapt to unforeseen obstacles, they can be used for exploration and surveillance missions in outdoor or unknown environments, such as search and rescue operations, environmental monitoring, or mapping of inaccessible areas.

3. **Rehabilitation and Prosthetics**: The research in robust and safe legged locomotion can also have implications in the field of rehabilitation and prosthetics. By developing advanced algorithms and frameworks, we can enhance the locomotion capabilities of assistive devices, such as exoskeletons or prosthetic limbs, allowing individuals with mobility impairments to regain independence and mobility.

{{< youtube ocAZtHr07Fw >}}

### Summary

In summary, our research project focuses on developing a hierarchical reinforcement learning framework for robust and safe legged locomotion. By leveraging the concept of hierarchical reinforcement learning, we aim to decompose the legged locomotion task into simpler sub-tasks and enable the robot to learn and adapt its locomotion skills in a layered fashion. This approach addresses the challenges faced by traditional end-to-end reinforcement learning algorithms, such as sampling inefficiency, lengthy training, and the sim-to-real gap. The transformative nature of the proposed work stems from its ability to make theoretical and practical advances in enabling safe and dynamic mobility on legged robots and lower-body exoskeletons in the real-world environment. The results will facilitate inroads into a broad application domains of bipedal robots, and ultimately, improves the quality of life of millions via restored locomotion with powered lower-limb exoskeletons.